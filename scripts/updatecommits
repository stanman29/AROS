#!/usr/bin/python

# Script for translating GitHubs RSS feed to html for including
# in www.aros.org's commits section.
# The result will be stored in htdocs

import urllib2
import ssl
import re
import HTMLParser

# We must set the encoding or HTMLParser().unescape() fails with error
# "UnicodeDecodeError: 'ascii' codec can't decode byte..."
import datetime
import sys  
reload(sys)  
sys.setdefaultencoding('utf8')

# regex for parsing a GitHub RSS item
rssregithub = re.compile(r'''<entry>.*?
<link \s+(.+?)\s+ href="(?P<link>.*?)"/>.*?
<title>(\s+)(?P<commit>.*?)(\s+)</title>.*?
<updated>(?P<pubDate>.*?)</updated>.*?
<name>(?P<creator>.*?)</name>.*?
<content\s+(.+?)">(\s+)(?P<description>.*?)</content>.*?
</entry>''',
re.DOTALL | re.VERBOSE)

# regex for parsing a track RSS item
rssretrack = re.compile(r'''<item>.*?
<title>.*?\[(?P<commit>.*?)\].*?</title>.*?
<dc:creator>(?P<creator>.*?)</dc:creator>.*?
<pubDate>(?P<pubDate>.*?)</pubDate>.*?
<link>(?P<link>.*?)</link>.*?
<description>(?P<description>.*?)</description>.*?
</item>''',
re.DOTALL | re.VERBOSE)

#count = 14 # number of entries
rsspath='https://github.com/aros-development-team/AROS/commits.atom'
ctx = ssl.SSLContext(ssl.PROTOCOL_SSLv23)
rssfile = urllib2.urlopen(rsspath, context=ctx)
#rssfile = urllib2.urlopen(rsspath)
content = rssfile.read()
rssfile.close()

targetpath='/home/project-web/aros/htdocs/commits.php'
targetfile = open(targetpath, 'w')

# output of the content in html format

targetfile.write('''
<!DOCTYPE html>
<html>
<head>
<title>AROS commits</title>
<meta charset="UTF-8">
<meta name="lastupdate" content="''' + str(datetime.datetime.now()) + '''">
<link rel="stylesheet" href="/aros.css">
</head>
<body>
<!-- This file is automaticaly generated by the AROS/scripts/updatecommits script, as a cron job -->\n
''')

for entry in rssregithub.finditer(content):
    targetfile.write('''
<h2><a href="%s" target="_top">%s | %s | %s </a></h2>
%s\n''' % (
    entry.group('link'),
    HTMLParser.HTMLParser().unescape(entry.group('commit')),
    HTMLParser.HTMLParser().unescape(entry.group('creator')),
    HTMLParser.HTMLParser().unescape(entry.group('pubDate')),
    HTMLParser.HTMLParser().unescape(entry.group('description'))))

targetfile.write('</body>\n</html>\n')

targetfile.close()
